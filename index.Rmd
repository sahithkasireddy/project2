---
title: 'Project 2: Data Mining, Classification, Prediction'
author: "SDS322E"
date: ''
output:
  html_document:
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
  pdf_document:
    toc: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, fig.align = "center", warning = F, message = F,
tidy=TRUE, tidy.opts=list(width.cutoff=60), R.options=list(max.print=100))

class_diag <- function(score, truth, positive, cutoff=.5){

  pred <- factor(score>cutoff,levels=c("TRUE","FALSE"))
  truth <- factor(truth==positive, levels=c("TRUE","FALSE"))

  tab<-table(truth, pred)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[1,1]/rowSums(tab)[1]
  spec=tab[2,2]/rowSums(tab)[2]
  ppv=tab[1,1]/colSums(tab)[1]

#CALCULATE F1
  f1=2*(sens*ppv)/(sens+ppv)
  
#CALCULATE EXACT AUC
  truth<-as.numeric(truth=="TRUE")
  ord<-order(score, decreasing=TRUE)
  score <- score[ord]; truth <- truth[ord]
  TPR=cumsum(truth)/max(1,sum(truth))
  FPR=cumsum(!truth)/max(1,sum(!truth))
  dup<-c(score[-1]>=score[-length(score)], FALSE)
  TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)
  n <- length(TPR)
  auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )
  round(data.frame(acc,sens,spec,ppv,f1,ba=(sens+spec)/2,auc, row.names = "Metrics"),4)
}
```

# Mining, Classification, Prediction

## Sahith Kasireddy, sk48663

### Introduction 


```{R}
#Reading and Adjusting Dataset
library(dplyr)
library(tidyverse)
hfi <- read.csv(file = 'hfi.csv')
hfi <- hfi %>% rename("Country" = `countries`, "Year" = year, "Region" = region) %>% select(-c(1,3))
hfi<- hfi %>% mutate_all(na_if,"")
hfi<- hfi %>% mutate_all(na_if,"..")

hfi <- hfi %>% select(c(1:3), pf_religion, ef_legal_gender, pf_expression, pf_movement, pf_rol, ef_regulation, ef_government, hf_score)
hfi<- hfi%>%filter(!if_all(c(4:11), is.na))

#Creation of A New Binary Variable: English-Speaking
hfi<- hfi %>% mutate(English_Speaking= case_when(Country == "United States"|Country == "New Zealand"|Country == "United Kingdom"|Country == "Canada"|Country == "Singapore"|Country == "Australia"|Country == "Ireland"|Country == "Ireland"|Country == "Trinidad and Tobago"|Country == "Guyana"|Country == "Bahamas"|Country == "Belize"|Country == "Barbados" ~ 1, Country != "United States" & Country != "New Zealand" & Country != "United Kingdom" & Country != "Canada" & Country != "Singapore" & Country != "Australia" & Country != "Ireland" & Country != "Ireland" & Country != "Trinidad and Tobago" & Country != "Guyana" & Country != "Bahamas" & Country != "Belize" & Country != "Barbados" ~ 0))

#Creating New Dataset Without Any Categorical Variables or NA for Cluster Analysis
hfi <- hfi %>% na.omit()
hfinocat <- hfi %>% select(-c(1:3, 12))


```

### Cluster Analysis

```{R}
#Picking Cluster Based on Average Silhouette Width
library(cluster)
sil_width<-vector() #empty vector to hold mean sil width
for(i in 2:10){
kms <- kmeans(hfinocat,centers=i) #compute k-means solution for each k
sil <- silhouette(kms$cluster,dist(hfinocat)) #get sil widths
sil_width[i]<-mean(sil[,3]) #take averages (higher is better)
}
ggplot()+geom_line(aes(x=1:10,y=sil_width))+scale_x_continuous(name="k",breaks=1:10)

#Pam Analysis
pam1 <- hfinocat %>% pam(k=2) #use the pam function
pam1

pamclust<- hfinocat %>% mutate(cluster=as.factor(pam1$clustering))
pamclust %>% group_by(cluster) %>% summarize_if(is.numeric,mean,na.rm=T)
hfinocat%>%slice(pam1$id.med)

#Visualizing Clusters with GGpairs
library(GGally)
pamclust %>% ggpairs(cols = 1:8, aes(color = cluster))



```

Discussion of clustering here
    
    
### Dimensionality Reduction with PCA

```{R}
#PCA analysis
library(cluster)
hfinocat_nums<- hfinocat %>% select_if(is.numeric) %>% scale()
rownames(hfinocat_nums)<-hfinocat$Name
hfinocat_pca<-princomp(hfinocat_nums)
names(hfinocat_pca)

summary(hfinocat_pca, loadings=T)

eigval<-hfinocat_pca$sdev^2 #square to convert SDs to eigenvalues
varprop=round(eigval/sum(eigval), 2) #proportion of var explained by each PC
round(cumsum(eigval)/sum(eigval), 2) #cumulative proportion of variance

#PC cumulative proportion graph
ggplot() + geom_bar(aes(y=varprop, x=1:8), stat="identity") + xlab("") + geom_path(aes(y=varprop, x=1:8)) + 
  geom_text(aes(x=1:8, y=varprop, label=round(varprop, 2)), vjust=1, col="white", size=5) + 
  scale_y_continuous(breaks=seq(0, .6, .2), labels = scales::percent) + 
  scale_x_continuous(breaks=1:8)


```
From the graph, it is evident that the first 4 PCs would attain a cumulative proportion of 0.85; therefore, 5 PCs are good. The first PCA shows a positive relationship betweeen every variable (except ef_government). This is the general variation in the set. The second PCA shows that countries that have low pf_rol, ef_regulation, and bad human freedom scores overall, are good for other categories. The third 

###  Linear Classifier

```{R}
#Logistic Regression Analysis
fit <- glm(English_Speaking ~ pf_religion + ef_legal_gender + pf_expression + pf_movement + pf_rol + ef_regulation + ef_government + hf_score, data=hfi, family="binomial")
score <- predict(fit, type="response")
score %>% round(3) %>% head()

#Class Diag Performance
class_diag(score,hfi$English_Speaking,positive=1)

#Confusion Matrix
y <- hfi$English_Speaking
y_hat <- sample(c("English-Speaking","Not English-Speaking"), size=length(y), replace=T)
y_hat <- factor(y_hat, levels=c("English-Speaking","Not English-Speaking"))
table(actual = y, predicted = y_hat) %>% addmargins

#hfi %>% mutate(score=score) %>% ggplot(aes(pf_religion + ef_legal_gender + pf_expression + pf_movement + pf_rol + ef_regulation + ef_government + hf_score,English_Speaking))+geom_point(aes(color=score>.5)) + geom_smooth(method="glm", se=F,method.args = list(family = "binomial"))+ylim(0,1)+geom_hline(yintercept=.5, lty=2)

```

```{R}
#K Fold Cross Validation
k=10 
data<-hfi[sample(nrow(hfi)),]
folds<-cut(seq(1:nrow(data)),breaks=k,labels=F) #create folds
diags<-NULL
for(i in 1:k){
  ## Create training and test sets
  train<-data[folds!=i,]
  test<-data[folds==i,]
  truth<-test$English_Speaking
  ## Train model on training set
  fit<-glm(English_Speaking~pf_religion + ef_legal_gender + pf_expression + pf_movement + pf_rol + ef_regulation + ef_government + hf_score,data=train,family="binomial")
  probs<-predict(fit,newdata = test,type="response")
  ## Test model on test set (save all k results)
  diags<-rbind(diags,class_diag(probs,truth, positive=1))
}
summarize_all(diags,mean)

```

The AUC is 0.92, which indicates that the model is great (AUCs above .90 ar excellent). The model for cross-validation also seems to be great, considering that the AUC is 0.91073. 

### Non-Parametric Classifier

```{R}
#K Nearest Neighbors Classifier
library(caret)
knn_fit <- knn3(factor(English_Speaking==1,levels=c("TRUE","FALSE")) ~ pf_religion + ef_legal_gender + pf_expression + pf_movement + pf_rol + ef_regulation + ef_government + hf_score, data=hfi, k=5)
y_hat_knn <- predict(knn_fit,hfi)
y_hat_knn

#Confusion Matrix
table(truth= factor(hfi$English_Speaking==1, levels=c("TRUE","FALSE")),
prediction= factor(y_hat_knn[,1]>.5, levels=c("TRUE","FALSE"))) %>% addmargins

#Class Diag Performance
class_diag(y_hat_knn[,1],hfi$English_Speaking, positive=1)
```

```{R}

#K-Fold Cross Validation
k=10 #choose number of folds
data<-hfi[sample(nrow(hfi)),] #randomly order rows
folds<-cut(seq(1:nrow(hfi)),breaks=k,labels=F) #create 10 folds
diags<-NULL
for(i in 1:k){
  ## Create training and test sets
  train<-data[folds!=i,]
  test<-data[folds==i,]
  truth<-test$English_Speaking
  ## Train model on training set
  fit<-knn3(English_Speaking~pf_religion + ef_legal_gender + pf_expression + pf_movement + pf_rol + ef_regulation + ef_government + hf_score,data=hfi)
  probs<-predict(fit,newdata = test)[,2]
  ## Test model on test set (save all k results)
  diags<-rbind(diags,class_diag(probs,truth, positive=1))
  }
summarize_all(diags,mean) 
```

The AUC is 0.9991 when using k-nearest neighbors for the Non-Parametric Classifier. This is excellent because is is almost near a perfect score of 1. The AUC of the cross-validation is also excellent because it is 0.99905. The confusion matrix indicates that there are very few false negatives and false positives. 


### Regression/Numeric Prediction

```{R}

#Regression Tree
library(rpart); library(rpart.plot)
fit_tree<- rpart(English_Speaking~pf_religion + ef_legal_gender + pf_expression + pf_movement + pf_rol + ef_regulation + ef_government + hf_score, data=hfi)
rpart.plot(fit_tree)

fit_tree <- train(English_Speaking~pf_religion + ef_legal_gender + pf_expression + pf_movement + pf_rol + ef_regulation + ef_government + hf_score, data=hfi, method="rpart")

fit_tree$bestTune

rpart.plot(fit_tree$finalModel)

#MSE
fit_MSE<-lm(hf_score~pf_religion + pf_expression + ef_government,data=hfi) 
yhat<-predict(fit_MSE) 
mean((hfi$hf_score-yhat)^2)

#K-Fold Cross Validation & Average MSE
k=5 #choose number of folds
data<-hfi[sample(nrow(hfi)),] #randomly order rows
folds<-cut(seq(1:nrow(hfi)),breaks=k,labels=F) #create folds
diags<-NULL
for(i in 1:k){
  train<-data[folds!=i,]
  test<-data[folds==i,]
  ## Fit linear regression model to training set
  fit<-lm(hf_score~pf_religion + pf_expression + ef_government,data=hfi)
  ## Get predictions/y-hats on test set (fold i)
  yhat<-predict(fit,newdata=test)
  ## Compute prediction error (MSE) for fold i
  diags<-mean((test$hf_score-yhat)^2)
}

mean(diags)

```

```{R}

```

Discussion

### Python 

```{R}
library(reticulate)

```

```{python}
hi = "Hello"


```

Discussion

### Concluding Remarks

Include concluding remarks here, if any




